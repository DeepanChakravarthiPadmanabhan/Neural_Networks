{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team Members:\n",
    "\n",
    "* Deepan Chakravarthi Padmanabhan\n",
    "* Jaswanth Bandlamudi\n",
    "* Muhammad Umer Ahmed Khan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data:\n",
    "\n",
    "1. Files used for compiling the positive samples (living skin): 'Archiv/Referenz-Haut_6-Klassen.csv' and 'Archiv2016/2016skin.csv'.\n",
    "2. Files used for compiling the negative samples (non-living skin): 'Archiv2016/2016material.csv', 'Archiv2016/2016material-fake.csv', 'Archiv/Fleisch.csv', 'Archiv/Stoff.csv', 'Archiv/Holz.csv', and 'Archiv/Leder.csv'.\n",
    "\n",
    "## Process flow:\n",
    "\n",
    "$$\\text{Data: Raw data provided in Archiv and Archiv 2016} \\\\ \\downarrow  \\\\ \\text{Data cleaning: Features with Nan values are removed in each file}  \\\\ \\downarrow\\\\   \\text{Visualization: Plot spectral data of each material provided} \\\\ \\downarrow \\\\ \\text{Combined files using same features alone. Subsampled archiv 2016 and dropped 400-660 from archiv} \\\\ \\downarrow \\\\\\text{Feature extraction: PCA- Extracted 5 features and normalized} \\\\ \\downarrow \\\\ \\text{Compiled positive and negative samples with labels} \\\\ \\downarrow \\\\ \\text{Shuffled data} \\\\ \\downarrow \\\\ \\text{Split train-test data (66.66%-33.33%)}\\\\ \\downarrow \\\\ \\text{Classification (Training): } \\textbf{SVM-Linear Kernel, SVM-RBF Kernel, Multi-Layer Perceptron, Random Forest}\\\\ \\downarrow \\\\ \\text{Classifier testing and validation} \\\\ \\downarrow\\\\ \\text{Visualize classification metrics for comparison: }\\textbf{Accuracy, Precision, Recall, Model memory size, Training time}$$ \n",
    "\n",
    "##### Reported cross-validation- mean roc_auc score for each classifier.  #####\n",
    "\n",
    "## Results and discussion:\n",
    "\n",
    "##### Provided at the end of the notebook #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, learning_curve, ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, classification_report \n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from sklearn import decomposition, model_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from memory_profiler import profile\n",
    "%load_ext memory_profiler\n",
    "\n",
    "# Memeory profiler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "def read_data(fileName, decimal_):\n",
    "    data = pd.read_csv(fileName, decimal = decimal_, delimiter=';', encoding='utf8')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading all data files\n",
    "\n",
    "data_material = read_data('Archiv2016/2016material.csv', decimal_='.')\n",
    "data_fake_material = read_data('Archiv2016/2016material-fake.csv', decimal_='.')\n",
    "data_skin = read_data('Archiv2016/2016skin.csv', decimal_='.')\n",
    "data_reference = read_data('Archiv2016/Referenz-Haut_6-Klassen.csv', decimal_=',')\n",
    "\n",
    "data_flesh = read_data('Archiv/Fleisch.csv', decimal_=',')\n",
    "data_stoff = read_data('Archiv/Stoff.csv', decimal_=',')\n",
    "data_holz = read_data('Archiv/Holz.csv', decimal_=',')\n",
    "data_leder = read_data('Archiv/Leder.csv', decimal_=',')\n",
    "data_2reference = read_data('Archiv/Referenz-Haut_6-Klassen.csv', decimal_=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neglecting features (wavelength) with Nan values\n",
    "\n",
    "data_material = data_material.dropna()\n",
    "data_fake_material = data_fake_material.dropna()\n",
    "data_skin = data_skin.dropna()\n",
    "data_reference = data_reference.dropna()\n",
    "data_flesh = data_flesh.dropna()\n",
    "data_stoff = data_stoff.dropna()\n",
    "data_holz = data_holz.dropna()\n",
    "data_leder = data_leder.dropna()\n",
    "data_2reference = data_2reference.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting spectra\n",
    "def plot_spectra(data, title):  \n",
    "    x = list(data.iloc[:,0])\n",
    "    columns = data.columns\n",
    "    plt.figure(figsize=(12,8))\n",
    "    for i in columns[1:]:\n",
    "        plt.plot(x,data[i])\n",
    "    plt.xlabel('Wavelength (nm)')\n",
    "    plt.ylabel('Intensity')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_spectra(data_material,'2016_material')\n",
    "plot_spectra(data_fake_material,'2016_fake_material')\n",
    "plot_spectra(data_skin,'2016_skin')\n",
    "plot_spectra(data_reference,'2016_reference')\n",
    "\n",
    "plot_spectra(data_flesh,'flesh')\n",
    "plot_spectra(data_stoff,'stoff')\n",
    "plot_spectra(data_holz,'holz')\n",
    "plot_spectra(data_leder,'leder')\n",
    "plot_spectra(data_2reference, 'archiv skin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "1. Referenz-Haut_6-Klassen.csv in archiv and archiv 2016 are the same.\n",
    "\n",
    "2. As seen above from the graphs all the materials are tested in various wavelengths making the number of features (along the x axis) unequal. In order to take a common feature representation numerous methods like imputation, feature split, dimensionality reduction can be applied as per [1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    x = df.values #returns a numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df = pd.DataFrame(x_scaled)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_(X, k):\n",
    "    # PCA for the data and taking k features\n",
    "    pca = decomposition.PCA(n_components=k)\n",
    "    pca_data  = pca.fit_transform(X.T)\n",
    "    return pca_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_material = normalize(data_material.iloc[:,1:])\n",
    "data_fake_material = normalize(data_fake_material.iloc[:,1:])\n",
    "data_flesh = normalize(data_flesh.iloc[:,1:])\n",
    "data_stoff = normalize(data_stoff.iloc[:,1:])\n",
    "data_holz = normalize(data_holz.iloc[:,1:])\n",
    "data_leder = normalize(data_leder.iloc[:,1:])\n",
    "\n",
    "data_skin = normalize(data_skin.iloc[:,1:])\n",
    "data_reference = normalize(data_reference.iloc[:,1:])\n",
    "data_2reference = normalize(data_2reference.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_material.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining PCA data. \n",
    "\n",
    "data_material_pca = PCA_(data_material, 5)\n",
    "data_fake_material_pca = PCA_(data_fake_material, 5)\n",
    "data_flesh_pca = PCA_(data_flesh, 5)\n",
    "data_stoff_pca = PCA_(data_stoff, 5)\n",
    "data_holz_pca = PCA_(data_holz, 5)\n",
    "data_leder_pca = PCA_(data_leder, 5)\n",
    "\n",
    "data_skin_pca = PCA_(data_skin, 5)\n",
    "data_reference_pca = PCA_(data_reference, 5)\n",
    "data_2reference_pca = PCA_(data_2reference, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_material_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_array(x):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    return x_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_material_pca = normalize_array(data_material_pca)\n",
    "data_fake_material_pca = normalize_array(data_fake_material_pca)\n",
    "data_flesh_pca = normalize_array(data_flesh_pca)\n",
    "data_stoff_pca = normalize_array(data_stoff_pca)\n",
    "data_holz_pca = normalize_array(data_holz_pca)\n",
    "data_leder_pca = normalize_array(data_leder_pca)\n",
    "\n",
    "data_skin_pca = normalize_array(data_skin_pca)\n",
    "data_reference_pca = normalize_array(data_reference_pca)\n",
    "data_2reference_pca = normalize_array(data_2reference_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labelling data \n",
    "\n",
    "def get_data_labels_pca(data, label_type):\n",
    "    columns = data.shape[0]\n",
    "    label_value = np.ones(((columns),1), dtype=int)\n",
    "    label_value.fill(label_type)\n",
    "    data = np.append(data, label_value, axis=1)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label 1 - non living materials\n",
    "# label 0 - living skin\n",
    "\n",
    "# Compiling dataset\n",
    "data_material_train = get_data_labels_pca(data_material_pca, 1)\n",
    "data_fake_material_train = get_data_labels_pca(data_fake_material_pca, 1)\n",
    "data_flesh_train = get_data_labels_pca(data_flesh_pca, 1)\n",
    "data_stoff_train = get_data_labels_pca(data_stoff_pca, 1)\n",
    "data_holz_train = get_data_labels_pca(data_holz_pca, 1)\n",
    "data_leder_train = get_data_labels_pca(data_leder_pca, 1)\n",
    "\n",
    "data_skin_train = get_data_labels_pca(data_skin_pca, 0)\n",
    "data_reference_train = get_data_labels_pca(data_reference_pca, 0)\n",
    "data_2reference_train = get_data_labels_pca(data_2reference_pca,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_data = np.append(data_skin_train, data_reference_train, axis=0) # Skin\n",
    "# Append all negative data together\n",
    "neg_data = np.append(data_material_train, data_fake_material_train, axis=0) # Non skin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_data_X = pos_data[:,0:-1]\n",
    "pos_data_y = pos_data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_data_X = neg_data[:,0:-1]\n",
    "neg_data_y = neg_data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(pos_data_X, neg_data_X, axis=0)\n",
    "y = np.append(pos_data_y, neg_data_y, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X = Features and y = labels are ready for learning and developing classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the dataset\n",
    "X, y = shuffle(X, y)\n",
    "\n",
    "# Splitting train-test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Linear\n",
    "svm_linear = svm.SVC(C=10, kernel='linear', gamma='auto')\n",
    "start = time.time()\n",
    "%memit svm_linear.fit(X_train,y_train)\n",
    "end = time.time()\n",
    "svm_linear_time = end - start\n",
    "print(\"Training time taken for SVM-Linear kernel (in seconds): \",end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_linear_fun(X_train,y_train):\n",
    "    svm_linear = svm.SVC(C=10, kernel='linear', gamma='auto')\n",
    "    start = time.time()\n",
    "    svm_linear.fit(X_train,y_train)\n",
    "    end = time.time()\n",
    "    svm_linear_time = end - start\n",
    "    print(\"Training time taken for SVM-Linear kernel (in seconds): \",end - start)\n",
    "    \n",
    "%memit svm_linear_fun(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "%memit svm_predict = svm_linear.predict(X_test)\n",
    "\n",
    "print(\"=== Confusion Matrix SVM-Linear Kernel Classifier===\")\n",
    "print(confusion_matrix(y_test, svm_predict))\n",
    "print('\\n')\n",
    "\n",
    "print(\"=== Classification Report SVM-Linear Kernel Classifier===\")\n",
    "print(classification_report(y_test, svm_predict))\n",
    "print('\\n')\n",
    "\n",
    "print(\"=== Accuracy SVM-Linear Kernel Classifier===\")\n",
    "svm_linear_accuracy = accuracy_score(y_test, svm_predict)\n",
    "print(svm_linear_accuracy)\n",
    "print('\\n')\n",
    "\n",
    "print(\"=== Precision SVM-Linear Kernel Classifier===\")\n",
    "svm_linear_precision = precision_score(y_test, svm_predict)\n",
    "print(svm_linear_precision)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(\"=== Recall SVM-Linear Kernel Classifier===\")\n",
    "svm_linear_recall = recall_score(y_test, svm_predict)\n",
    "print(svm_linear_recall)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear_cv = svm.SVC(C=10, kernel='linear', gamma='auto')\n",
    "start = time.time()\n",
    "svm_linear_cv_score = cross_val_score(svm_linear_cv, X, y, cv=5, scoring='roc_auc')\n",
    "end = time.time()\n",
    "print(\"=== All AUC Scores SVM-Linear Classifier===\")\n",
    "\n",
    "print(svm_linear_cv_score)\n",
    "print('\\n')\n",
    "\n",
    "print(\"=== Mean AUC Score SVM-Linear Kernel Classifier: ===\")\n",
    "print(svm_linear_cv_score.mean())\n",
    "print('\\n')\n",
    "\n",
    "print(\"Time taken for cross validation SVM-Linear kernel (in seconds): \",end - start,\"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using archiv and archiv 2016 folder data\n",
    "\n",
    "Entire dataset is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_data = np.append(neg_data, data_flesh_train, axis=0)\n",
    "neg_data = np.append(neg_data, data_stoff_train, axis=0)\n",
    "neg_data = np.append(neg_data, data_holz_train, axis=0)\n",
    "neg_data = np.append(neg_data, data_leder_train, axis=0)\n",
    "\n",
    "neg_data_X = neg_data[:,0:-1]\n",
    "neg_data_y = neg_data[:,-1]\n",
    "\n",
    "X = np.append(pos_data_X, neg_data_X, axis=0)\n",
    "y = np.append(pos_data_y, neg_data_y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "# Shuffling the dataset\n",
    "X, y = shuffle(X, y)\n",
    "\n",
    "# Splitting train-test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear = svm.SVC(C=10, kernel='linear')\n",
    "start = time.time()\n",
    "%memit svm_linear.fit(X_train,y_train)\n",
    "end = time.time()\n",
    "svm_linear_time = end - start\n",
    "print(\"Training time taken for SVM-Linear Kernel (in seconds): \",svm_linear_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_linear_fun(X_train,y_train):\n",
    "    svm_linear = svm.SVC(C=10, kernel='linear', gamma='auto')\n",
    "    start = time.time()\n",
    "    svm_linear.fit(X_train,y_train)\n",
    "    end = time.time()\n",
    "    svm_linear_time = end - start\n",
    "    print(\"Training time taken for SVM-Linear kernel (in seconds): \",end - start)\n",
    "    \n",
    "%memit svm_linear_fun(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "%memit svm_predict = svm_linear.predict(X_test)\n",
    "\n",
    "print(\"=== Confusion Matrix SVM-Linear Kernel Classifier===\")\n",
    "print(confusion_matrix(y_test, svm_predict))\n",
    "print('\\n')\n",
    "\n",
    "print(\"=== Classification Report SVM-Linear Kernel Classifier===\")\n",
    "print(classification_report(y_test, svm_predict))\n",
    "print('\\n')\n",
    "\n",
    "print(\"=== Accuracy SVM-Linear Kernel Classifier===\")\n",
    "svm_linear_accuracy = accuracy_score(y_test, svm_predict)\n",
    "print(svm_linear_accuracy)\n",
    "print('\\n')\n",
    "\n",
    "print(\"=== Precision SVM-Linear Kernel Classifier===\")\n",
    "svm_linear_precision = precision_score(y_test, svm_predict)\n",
    "print(svm_linear_precision)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(\"=== Recall SVM-Linear Kernel Classifier===\")\n",
    "svm_linear_recall = recall_score(y_test, svm_predict)\n",
    "print(svm_linear_recall)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear_cv = svm.SVC(C=10, kernel='linear')\n",
    "svm_linear_cv_score = cross_val_score(svm_linear_cv, X, y, cv=5, scoring='roc_auc')\n",
    "\n",
    "print(\"=== All AUC Scores SVM-Linear Kernel Classifier===\")\n",
    "\n",
    "print(svm_linear_cv_score)\n",
    "print('\\n')\n",
    "\n",
    "print(\"=== Mean AUC Score SVM-Linear Kernel Classifier ===\")\n",
    "print(svm_linear_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    print(\"CV score, test_scores\", test_scores_mean)\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "f = plt.figure(figsize=(16,5))\n",
    "plt.subplots_adjust(left=None,bottom=0.1,top=0.9,wspace=0.2,hspace=0.5)\n",
    "\n",
    "estimator = svm_linear\n",
    "title = r\"Learning Curves\"\n",
    "plot_learning_curve(estimator, title, X, y, ylim=(0, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "fig1 = plt.gcf()\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radial Basis Function Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(X, y)\n",
    "\n",
    "# Splitting train-test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf = svm.SVC(C=1, kernel='rbf', gamma=10)\n",
    "start = time.time()\n",
    "%memit svm_rbf.fit(X_train,y_train)\n",
    "end = time.time()\n",
    "svm_rbf_time = end - start\n",
    "print(\"Training time taken for SVM-RBF Kernel (in seconds): \",svm_rbf_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_rbf_fun(X_train,y_train):\n",
    "    svm_linear = svm.SVC(C=10, kernel='rbf', gamma=10)\n",
    "    start = time.time()\n",
    "    svm_linear.fit(X_train,y_train)\n",
    "    end = time.time()\n",
    "    svm_linear_time = end - start\n",
    "    print(\"Training time taken for SVM-Linear kernel (in seconds): \",end - start)\n",
    "    \n",
    "%memit svm_rbf_fun(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "%memit svm_predict = svm_rbf.predict(X_test)\n",
    "\n",
    "print(\"=== Confusion Matrix SVM-RBF Kernel Classifier===\")\n",
    "print(confusion_matrix(y_test, svm_predict))\n",
    "print('\\n')\n",
    "\n",
    "print(\"=== Classification Report SVM-RBF Kernel Classifier===\")\n",
    "print(classification_report(y_test, svm_predict))\n",
    "print('\\n')\n",
    "\n",
    "print(\"=== Accuracy SVM-RBF Kernel Classifier===\")\n",
    "svm_rbf_accuracy = accuracy_score(y_test, svm_predict)\n",
    "print(svm_rbf_accuracy)\n",
    "print('\\n')\n",
    "\n",
    "print(\"=== Precision SVM-RBF Kernel Classifier===\")\n",
    "svm_rbf_precision = precision_score(y_test, svm_predict)\n",
    "print(svm_rbf_precision)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(\"=== Recall SVM-RBF Kernel Classifier===\")\n",
    "svm_rbf_recall = recall_score(y_test, svm_predict)\n",
    "print(svm_rbf_recall)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_cv = svm.SVC(C=1, kernel='rbf', gamma=10)\n",
    "svm_rbf_cv_score = cross_val_score(svm_rbf_cv, X, y, cv=5, scoring='roc_auc')\n",
    "\n",
    "print(\"=== All AUC Scores SVM-RBF Kernel Classifier===\")\n",
    "\n",
    "print(svm_rbf_cv_score)\n",
    "print('\\n')\n",
    "\n",
    "print(\"=== Mean AUC Score SVM-RBF Kernel Classifier ===\")\n",
    "print(svm_rbf_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "f = plt.figure(figsize=(16,5))\n",
    "plt.subplots_adjust(left=None,bottom=0.1,top=0.9,wspace=0.2,hspace=0.5)\n",
    "\n",
    "estimator = svm_rbf\n",
    "title = r\"Learning Curves\"\n",
    "plot_learning_curve(estimator, title, X, y, ylim=(0, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "fig1 = plt.gcf()\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using sklearn\n",
    "\n",
    "# Hyper parameter optimization - Finding best parameters using Gridsearch\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(10,10,10), (5,10), (10,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "mlp_sklearn = MLPClassifier(max_iter=100, random_state=1)\n",
    "mlp_sklearn = model_selection.GridSearchCV(mlp_sklearn, parameter_space, n_jobs=-1, cv=3)\n",
    "%memit mlp_sklearn.fit(X_train, y_train)\n",
    "# Best model found by HPO\n",
    "print(\"Best model\", mlp_sklearn)\n",
    "predicted = mlp_sklearn.predict(X_test)\n",
    "\n",
    "print(\"=== Accuracy MLP Classifier===\")\n",
    "mlp_accuracy = accuracy_score(y_test, predicted)\n",
    "print(mlp_accuracy)\n",
    "print('\\n')\n",
    "\n",
    "print(\"=== Precision MLP Classifier===\")\n",
    "mlp_precision = precision_score(y_test, predicted)\n",
    "print(mlp_precision)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(\"=== Recall MLP Classifier===\")\n",
    "mlp_recall = recall_score(y_test, predicted)\n",
    "print(mlp_recall)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# MLP with 3 hidden layers and a output layer\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=66)\n",
    "input_ = Input(shape=(X_train.shape[1],)) # input\n",
    "hidden_1 = Dense(12, activation='relu')(input_) # inputs * weights \n",
    "hidden_2 = Dense(12, activation='relu')(hidden_1) # hidden * weights\n",
    "hidden_3 = Dense(12, activation='relu')(hidden_2)\n",
    "output_ = Dense(1, activation='sigmoid')(hidden_3)\n",
    "classifier = Model(input_, output_)\n",
    "\n",
    "# Optimizer and loss function definition\n",
    "classifier.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.01), metrics = ['accuracy'] )\n",
    "# For weight balancing on unbalanced dataset.\n",
    "weights = compute_class_weight('balanced', np.array([0,1]), y_train)\n",
    "\n",
    "start_ = time.time()\n",
    "%memit history = classifier.fit(X_train, y_train, batch_size=10, epochs=100, class_weight={0:weights[0],1:weights[1]})\n",
    "stop_ = time.time()\n",
    "predicted_labels = classifier.predict(X_test)\n",
    "predicted_labels = np.array([i > 0.5 for i in predicted_labels])\n",
    "# Map probabilities to class labels\n",
    "\n",
    "mlp_time = stop_ - start_\n",
    "predictions = predicted_labels\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "mlp_accuracy = accuracy_score(y_test, predictions)\n",
    "mlp_precision = precision_score(y_test, predictions, [1,0])\n",
    "mlp_recall = recall_score(y_test, predictions, [1,0])\n",
    "\n",
    "print (\"=== Confusion matrix of MLP Classifier===\")\n",
    "print (\"=== Depiction ===\\n\",np.array([[\"TP\", \"FN\"], [\"FP\", \"TN\"]]))\n",
    "print (\"=== Estimated values ===\\n\",confusion_matrix(y_test, predictions, [1,0]))\n",
    "print (\"=== Precision of MLP Classifier===\\n\",mlp_precision)\n",
    "print (\"=== Recall of MLP Classifier===\\n\",mlp_recall)\n",
    "print(\"=== Accuracy MLP Classifier===\\n\", mlp_accuracy)\n",
    "print(\"Training time taken for MLP with 3 hidden layers (in seconds): \",mlp_time)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# random forest model creation\n",
    "rfc = RandomForestClassifier()\n",
    "start = time.time()\n",
    "%memit rfc.fit(X_train,y_train)\n",
    "end = time.time()\n",
    "random_forest_time = end - start\n",
    "print(\"Training time taken for Random Forest with 10 estimators (in seconds): \",random_forest_time)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit rfc_predict = rfc.predict(X_test)\n",
    "\n",
    "print(\"=== Confusion Matrix Random forest Classifier===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "\n",
    "print(\"=== Classification Report Random forest Classifier===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "\n",
    "print(\"=== Accuracy Random forest Classifier===\")\n",
    "random_forest_accuracy = accuracy_score(y_test, rfc_predict)\n",
    "print(random_forest_accuracy)\n",
    "print('\\n')\n",
    "\n",
    "print(\"=== Precision Random forest Classifier===\")\n",
    "random_forest_precision = precision_score(y_test, rfc_predict)\n",
    "print(random_forest_precision)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(\"=== Recall Random forest Classifier===\")\n",
    "random_forest_recall = recall_score(y_test, rfc_predict)\n",
    "print(random_forest_recall)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_cv = RandomForestClassifier()\n",
    "rfc_cv_score = cross_val_score(rfc_cv, X, y, cv=5, scoring='roc_auc')\n",
    "\n",
    "print(\"=== All AUC Scores Random Forest Classifier===\")\n",
    "\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest Classifier: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "f = plt.figure(figsize=(16,5))\n",
    "plt.subplots_adjust(left=None,bottom=0.1,top=0.9,wspace=0.2,hspace=0.5)\n",
    "\n",
    "estimator = rfc\n",
    "title = r\"Learning Curves\"\n",
    "plot_learning_curve(estimator, title, X, y, ylim=(0, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "fig1 = plt.gcf()\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = [svm_linear_time, svm_rbf_time, mlp_time, random_forest_time]\n",
    "LABELS = ['svm_linear', 'svm_rbf', 'mlp', 'random_forest']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6), facecolor='white', dpi= 80)\n",
    "ax.vlines(x=LABELS, ymin=0, ymax=timer, color='firebrick', alpha=1, linewidth=20)\n",
    "\n",
    "# Annotate Text\n",
    "for i, value in enumerate(timer):\n",
    "    ax.text(i, value+0.05, round(value,3), horizontalalignment='center')\n",
    "plt.ylabel('Training time (in seconds)')\n",
    "plt.xlabel('Classifiers')\n",
    "plt.title('Classifiers training time taken comparison')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_ = [svm_linear_accuracy, svm_rbf_accuracy, mlp_accuracy, random_forest_accuracy]\n",
    "LABELS = ['svm_linear', 'svm_rbf', 'mlp', 'rf']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6), facecolor='white', dpi= 80)\n",
    "ax.vlines(x=LABELS, ymin=0, ymax=accuracy_, color='firebrick', alpha=1, linewidth=20)\n",
    "\n",
    "# Annotate Text\n",
    "for i, value in enumerate(accuracy_):\n",
    "    ax.text(i, value+0.01, round(value,3), horizontalalignment='center')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Classifiers')\n",
    "plt.title('Classifiers accuracy comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = [svm_linear_recall, svm_rbf_recall, mlp_recall, random_forest_recall]\n",
    "x_range = range(len(recall))\n",
    "LABELS = ['svm_linear', 'svm_rbf', 'mlp', 'rf']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6), facecolor='white', dpi= 80)\n",
    "ax.vlines(x=LABELS, ymin=0, ymax=recall, color='firebrick', alpha=1, linewidth=20)\n",
    "\n",
    "# Annotate Text\n",
    "for i, value in enumerate(recall):\n",
    "    ax.text(i, value+0.01, round(value,3), horizontalalignment='center')\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Classifiers')\n",
    "plt.title('Classifiers recall comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = [svm_linear_precision, svm_rbf_precision, mlp_precision, random_forest_precision]\n",
    "LABELS = ['svm_linear', 'svm_rbf', 'mlp', 'rf']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6), facecolor='white', dpi= 80)\n",
    "ax.vlines(x=LABELS, ymin=0, ymax=precision, color='firebrick', alpha=1, linewidth=20)\n",
    "\n",
    "# Annotate Text\n",
    "for i, value in enumerate(precision):\n",
    "    ax.text(i, value+0.01, round(value,3), horizontalalignment='center')\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Classifiers')\n",
    "plt.title('Classifiers precision comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "svm_linear_filename = 'svm_model.pkl'\n",
    "pickle.dump(svm_linear, open(svm_linear_filename, 'wb'))\n",
    "\n",
    "svm_rbf_filename = 'svm_model.pkl'\n",
    "pickle.dump(svm_rbf, open(svm_rbf_filename, 'wb'))\n",
    "\n",
    "mlp_filename = 'mlp_model.pkl'\n",
    "pickle.dump(classifier, open(mlp_filename, 'wb'))\n",
    "\n",
    "rfc_filename = 'rf_model.pkl'\n",
    "pickle.dump(rfc, open(rfc_filename, 'wb'))\n",
    "\n",
    "statinfo_svm_linear = os.path.getsize(svm_linear_filename)\n",
    "print(\"Memeory of the SVM-Linear Kernel model (in bytes):\",statinfo_svm_linear)\n",
    "\n",
    "statinfo_svm_rbf = os.path.getsize(svm_rbf_filename)\n",
    "print(\"Memeory of the SVM-RBF Kernel model (in bytes):\",statinfo_svm_rbf)\n",
    "\n",
    "statinfo_mlp = os.path.getsize(mlp_filename)\n",
    "print(\"Memeory of the MLP model (in bytes):\",statinfo_mlp)\n",
    "\n",
    "statinfo_rfc = os.path.getsize(rfc_filename)\n",
    "print(\"Memeory of the Random forest model (in bytes):\",statinfo_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = [statinfo_svm_linear, statinfo_svm_rbf, statinfo_mlp, statinfo_rfc]\n",
    "LABELS = ['svm_linear', 'svm_rbf', 'mlp', 'rf']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6), facecolor='white', dpi= 80)\n",
    "ax.vlines(x=LABELS, ymin=0, ymax=memory, color='firebrick', alpha=1, linewidth=20)\n",
    "\n",
    "# Annotate Text\n",
    "for i, value in enumerate(memory):\n",
    "    ax.text(i, value+1000, round(value,3), horizontalalignment='center')\n",
    "plt.ylabel('Model size (in bytes)')\n",
    "plt.xlabel('Classifiers')\n",
    "plt.title('Classifiers model memory size comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion:\n",
    "The classifiers are compared on 5 metrics: \n",
    "\n",
    "* Accuracy\n",
    "* Recall\n",
    "* Precision\n",
    "* Training time\n",
    "* Model memory size\n",
    "* Memory foot print\n",
    "\n",
    "\n",
    "The individual illustrations provided in results section compare the metrics and the winner among the classifier is SVM- Radial basis function kernel.\n",
    "\n",
    "SVM-RBF on 5 features extracted by perform Principal Component Analysis provides an accuracy of 97.8%.\n",
    "\n",
    "Since accuracy alone cannot be used to decide the best classifier for the given task, recall and precision is also analyzed. SVM-RBF is the winner of all classifiers comparing recall and precision too.\n",
    "\n",
    "MLP training time is more significantly higher than SVM-RBF.\n",
    "\n",
    "RF model size is significantly larger than SVM-RBF and MLP.\n",
    "\n",
    "On comparing all the metrics SVM-RBF stands out as shown in the above graphs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Emre Rencberoglu, \"Fundamental Techniques of Feature Engineering for Machine Learning\", Towards Datascience, Available at: https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114, Accessed on: 16.11.2019 [Online].\n",
    "\n",
    "2. Profiling and Optimizing in Jupyter Notebooks - A Comprehensive Guide by Muriz Serifovic\n",
    "https://towardsdatascience.com/speed-up-jupyter-notebooks-20716cbe2025 Accessed on:23-11-2019"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (study)",
   "language": "python",
   "name": "study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
